{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I imagine his virginity at 40 will also be ple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happiness can be found even in the darkest of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are your eyes swollen and squinty from all of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Purely practical note:\\n\\nNow that you have sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You look like you could be the spokesperson fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73307</th>\n",
       "      <td>I bet you wish you could transfer some of the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73308</th>\n",
       "      <td>I hope your dick is as big as your teeth, beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73309</th>\n",
       "      <td>You need to put the XXL butt plug down bro, I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73310</th>\n",
       "      <td>Do you actually have a neck or did you eat tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73311</th>\n",
       "      <td>I love your smile and the way you wear your hair.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comments  Type\n",
       "0      I imagine his virginity at 40 will also be ple...     0\n",
       "1      Happiness can be found even in the darkest of ...     1\n",
       "2      Are your eyes swollen and squinty from all of ...     0\n",
       "3      Purely practical note:\\n\\nNow that you have sh...     1\n",
       "4      You look like you could be the spokesperson fo...     1\n",
       "...                                                  ...   ...\n",
       "73307  I bet you wish you could transfer some of the ...     0\n",
       "73308  I hope your dick is as big as your teeth, beca...     0\n",
       "73309  You need to put the XXL butt plug down bro, I ...     0\n",
       "73310  Do you actually have a neck or did you eat tha...     0\n",
       "73311  I love your smile and the way you wear your hair.     1\n",
       "\n",
       "[73312 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Final_Dataset/final_dataset\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "0    36656\n",
       "1    36656\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Type').describe()\n",
    "df[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punctuation & Stop Words Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ketansharma14/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imagine virginity also pleated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness found even darkest times one remembe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyes swollen squinty loads random truckers you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purely practical note short hair first time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look like could spokesperson kind wholesome co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73307</th>\n",
       "      <td>bet wish could transfer fat thighs non existen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73308</th>\n",
       "      <td>hope dick big teeth looks one going want fuck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73309</th>\n",
       "      <td>need put xxl butt plug bro doubt anything left...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73310</th>\n",
       "      <td>actually neck eat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73311</th>\n",
       "      <td>love smile way wear hair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comments  Type\n",
       "0                         imagine virginity also pleated     0\n",
       "1      happiness found even darkest times one remembe...     1\n",
       "2      eyes swollen squinty loads random truckers you...     0\n",
       "3            purely practical note short hair first time     1\n",
       "4      look like could spokesperson kind wholesome co...     1\n",
       "...                                                  ...   ...\n",
       "73307  bet wish could transfer fat thighs non existen...     0\n",
       "73308      hope dick big teeth looks one going want fuck     0\n",
       "73309  need put xxl butt plug bro doubt anything left...     0\n",
       "73310                                  actually neck eat     0\n",
       "73311                           love smile way wear hair     1\n",
       "\n",
       "[73312 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc(comment):\n",
    "    punc = '''!()-[]}{;:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "    for ele in comment:\n",
    "        if ele in punc:\n",
    "            comment = comment.replace(ele, \"\")\n",
    "    \n",
    "    return comment\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I | re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "\n",
    "df[\"Comments\"] = df[\"Comments\"].apply(remove_punc)\n",
    "\n",
    "df[\"Comments\"] = df[\"Comments\"].apply(normalize_document)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Comments\"]\n",
    "y = df[\"Type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing, Padding The Sequences & Reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58649, 150, 1)\n",
      "(14663, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing Training & Test Data\n",
    "tokenizer = Tokenizer(num_words=1000, lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Padding Sequences\n",
    "max_len = 150\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=max_len)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One_Hot Encoding of Y Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58649, 2)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "def vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(50, input_shape=(max_len, 1), return_sequences=False))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_Classifier = vanilla_rnn()\n",
    "RNN_Classifier.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RNN_Classifier.predict(X_test)\n",
    "y_test_ = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input(\"Enter any sentence: \")\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a = np.array(a)\n",
    "a = pad_sequences(a, padding='post', maxlen=max_len)\n",
    "\n",
    "a = a.reshape((a.shape[0], a.shape[1], 1))\n",
    "\n",
    "prediction = RNN_Classifier.predict(np.array(a))\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
